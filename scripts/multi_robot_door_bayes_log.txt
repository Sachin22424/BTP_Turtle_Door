Multi-Robot Door Bayes Filter Log
===============================


--- robot1 Log ---
robot1: Moving to door1 at (3.0, 3.0)
robot1: Decided to push door1
robot1: Pushed door1 and observed it's closed
robot1: 
=== BAYES FILTER UPDATE FOR DOOR1 ===
robot1: ACTION: push, OBSERVATION: closed
robot1: 
Step 1: Prior belief bel(x_{t-1})
robot1:   bel(open) = 0.5000
robot1:   bel(closed) = 0.5000
robot1:   Verification: 0.5000 + 0.5000 = 1.0000
robot1: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot1:   Motion Model for action 'push':
robot1:     P(open | push, closed) = 0.8
robot1:     P(closed | push, closed) = 0.2
robot1:     P(open | push, open) = 1.0
robot1:     P(closed | push, open) = 0.0
robot1: 
  Prediction calculations:
robot1:     bel^-(open) = P(open|push,closed)*bel(closed) + P(open|push,open)*bel(open)
robot1:                 = 0.8 × 0.5000 + 1.0 × 0.5000
robot1:                 = 0.4000 + 0.5000 = 0.9000
robot1:     bel^-(closed) = P(closed|push,closed)*bel(closed) + P(closed|push,open)*bel(open)
robot1:                   = 0.2 × 0.5000 + 0.0 × 0.5000
robot1:                   = 0.1000 + 0.0000 = 0.1000
robot1: 
  Prediction result (before normalization):
robot1:     bel^-(open) = 0.9000
robot1:     bel^-(closed) = 0.1000
robot1:     Sum = 1.0000
robot1:   No normalization needed (sum ≈ 1.0)
robot1: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot1:   Sensor Model probabilities:
robot1:     P(observe_open | door_open) = 0.6
robot1:     P(observe_closed | door_open) = 0.4
robot1:     P(observe_open | door_closed) = 0.2
robot1:     P(observe_closed | door_closed) = 0.8
robot1: 
  Observed: closed
robot1:     P(observe_closed | door_open) = 0.4
robot1:     P(observe_closed | door_closed) = 0.8
robot1: 
  Correction calculations (before normalization):
robot1:     bel(open) ∝ P(closed|open) × bel^-(open) = 0.4 × 0.9000 = 0.3600
robot1:     bel(closed) ∝ P(closed|closed) × bel^-(closed) = 0.8 × 0.1000 = 0.0800
robot1: 
  Final Normalization:
robot1:     Sum before normalization = 0.3600 + 0.0800 = 0.4400
robot1:     Normalization constant η = 1/0.4400 = 2.2727
robot1:     Final bel(open) = 0.3600 × 2.2727 = 0.8182
robot1:     Final bel(closed) = 0.0800 × 2.2727 = 0.1818
robot1:     Verification: 0.8182 + 0.1818 = 1.0000
robot1: 
  WHY NORMALIZE?
robot1:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot1:     - The proportionality constant ensures ∑P(x|z) = 1
robot1:     - This maintains the probability distribution property
robot1:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot1:     - Alternative: Additive update would violate probability axioms
robot1: 
=== BAYES FILTER COMPLETE FOR DOOR1 ===
robot1: Can pass through door1

--- robot2 Log ---
robot2: Moving to door4 at (9.0, 7.0)
robot2: Decided to do nothing door4
robot2: Observed door4 is open
robot2: 
=== BAYES FILTER UPDATE FOR DOOR4 ===
robot2: ACTION: do nothing, OBSERVATION: open
robot2: 
Step 1: Prior belief bel(x_{t-1})
robot2:   bel(open) = 0.5000
robot2:   bel(closed) = 0.5000
robot2:   Verification: 0.5000 + 0.5000 = 1.0000
robot2: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot2:   Motion Model for action 'do nothing':
robot2:     P(open | do_nothing, open) = 1.0
robot2:     P(closed | do_nothing, open) = 0.0
robot2:     P(open | do_nothing, closed) = 0.0
robot2:     P(closed | do_nothing, closed) = 1.0
robot2: 
  Prediction calculations:
robot2:     bel^-(open) = 0.0 × 0.5000 + 1.0 × 0.5000 = 0.5000
robot2:     bel^-(closed) = 1.0 × 0.5000 + 0.0 × 0.5000 = 0.5000
robot2: 
  Prediction result (before normalization):
robot2:     bel^-(open) = 0.5000
robot2:     bel^-(closed) = 0.5000
robot2:     Sum = 1.0000
robot2:   No normalization needed (sum ≈ 1.0)
robot2: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot2:   Sensor Model probabilities:
robot2:     P(observe_open | door_open) = 0.6
robot2:     P(observe_closed | door_open) = 0.4
robot2:     P(observe_open | door_closed) = 0.2
robot2:     P(observe_closed | door_closed) = 0.8
robot2: 
  Observed: open
robot2:     P(observe_open | door_open) = 0.6
robot2:     P(observe_open | door_closed) = 0.2
robot2: 
  Correction calculations (before normalization):
robot2:     bel(open) ∝ P(open|obs) × bel^-(open) = 0.6 × 0.5000 = 0.3000
robot2:     bel(closed) ∝ P(open|closed) × bel^-(closed) = 0.2 × 0.5000 = 0.1000
robot2: 
  Final Normalization:
robot2:     Sum before normalization = 0.3000 + 0.1000 = 0.4000
robot2:     Normalization constant η = 1/0.4000 = 2.5000
robot2:     Final bel(open) = 0.3000 × 2.5000 = 0.7500
robot2:     Final bel(closed) = 0.1000 × 2.5000 = 0.2500
robot2:     Verification: 0.7500 + 0.2500 = 1.0000
robot2: 
  WHY NORMALIZE?
robot2:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot2:     - The proportionality constant ensures ∑P(x|z) = 1
robot2:     - This maintains the probability distribution property
robot2:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot2:     - Alternative: Additive update would violate probability axioms
robot2: 
=== BAYES FILTER COMPLETE FOR DOOR4 ===
robot2: Can pass through door4

--- robot1 Log ---
robot1: COMMUNICATION FAILED: Distance to robot2 = 10.38 > 3.0
robot1: Moving to door5 at (5.5, 5.5)
robot1: Decided to push door5
robot1: Pushed door5 and observed it's open
robot1: 
=== BAYES FILTER UPDATE FOR DOOR5 ===
robot1: ACTION: push, OBSERVATION: open
robot1: 
Step 1: Prior belief bel(x_{t-1})
robot1:   bel(open) = 0.5000
robot1:   bel(closed) = 0.5000
robot1:   Verification: 0.5000 + 0.5000 = 1.0000
robot1: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot1:   Motion Model for action 'push':
robot1:     P(open | push, closed) = 0.8
robot1:     P(closed | push, closed) = 0.2
robot1:     P(open | push, open) = 1.0
robot1:     P(closed | push, open) = 0.0
robot1: 
  Prediction calculations:
robot1:     bel^-(open) = P(open|push,closed)*bel(closed) + P(open|push,open)*bel(open)
robot1:                 = 0.8 × 0.5000 + 1.0 × 0.5000
robot1:                 = 0.4000 + 0.5000 = 0.9000
robot1:     bel^-(closed) = P(closed|push,closed)*bel(closed) + P(closed|push,open)*bel(open)
robot1:                   = 0.2 × 0.5000 + 0.0 × 0.5000
robot1:                   = 0.1000 + 0.0000 = 0.1000
robot1: 
  Prediction result (before normalization):
robot1:     bel^-(open) = 0.9000
robot1:     bel^-(closed) = 0.1000
robot1:     Sum = 1.0000
robot1:   No normalization needed (sum ≈ 1.0)
robot1: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot1:   Sensor Model probabilities:
robot1:     P(observe_open | door_open) = 0.6
robot1:     P(observe_closed | door_open) = 0.4
robot1:     P(observe_open | door_closed) = 0.2
robot1:     P(observe_closed | door_closed) = 0.8
robot1: 
  Observed: open
robot1:     P(observe_open | door_open) = 0.6
robot1:     P(observe_open | door_closed) = 0.2
robot1: 
  Correction calculations (before normalization):
robot1:     bel(open) ∝ P(open|obs) × bel^-(open) = 0.6 × 0.9000 = 0.5400
robot1:     bel(closed) ∝ P(open|closed) × bel^-(closed) = 0.2 × 0.1000 = 0.0200
robot1: 
  Final Normalization:
robot1:     Sum before normalization = 0.5400 + 0.0200 = 0.5600
robot1:     Normalization constant η = 1/0.5600 = 1.7857
robot1:     Final bel(open) = 0.5400 × 1.7857 = 0.9643
robot1:     Final bel(closed) = 0.0200 × 1.7857 = 0.0357
robot1:     Verification: 0.9643 + 0.0357 = 1.0000
robot1: 
  WHY NORMALIZE?
robot1:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot1:     - The proportionality constant ensures ∑P(x|z) = 1
robot1:     - This maintains the probability distribution property
robot1:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot1:     - Alternative: Additive update would violate probability axioms
robot1: 
=== BAYES FILTER COMPLETE FOR DOOR5 ===
robot1: Can pass through door5

--- robot2 Log ---
robot2: COMMUNICATION FAILED: Distance to robot1 = 8.11 > 3.0
robot2: Moving to door5 at (5.5, 5.5)
robot2: Decided to do nothing door5
robot2: Observed door5 is open
robot2: 
=== BAYES FILTER UPDATE FOR DOOR5 ===
robot2: ACTION: do nothing, OBSERVATION: open
robot2: 
Step 1: Prior belief bel(x_{t-1})
robot2:   bel(open) = 0.5000
robot2:   bel(closed) = 0.5000
robot2:   Verification: 0.5000 + 0.5000 = 1.0000
robot2: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot2:   Motion Model for action 'do nothing':
robot2:     P(open | do_nothing, open) = 1.0
robot2:     P(closed | do_nothing, open) = 0.0
robot2:     P(open | do_nothing, closed) = 0.0
robot2:     P(closed | do_nothing, closed) = 1.0
robot2: 
  Prediction calculations:
robot2:     bel^-(open) = 0.0 × 0.5000 + 1.0 × 0.5000 = 0.5000
robot2:     bel^-(closed) = 1.0 × 0.5000 + 0.0 × 0.5000 = 0.5000
robot2: 
  Prediction result (before normalization):
robot2:     bel^-(open) = 0.5000
robot2:     bel^-(closed) = 0.5000
robot2:     Sum = 1.0000
robot2:   No normalization needed (sum ≈ 1.0)
robot2: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot2:   Sensor Model probabilities:
robot2:     P(observe_open | door_open) = 0.6
robot2:     P(observe_closed | door_open) = 0.4
robot2:     P(observe_open | door_closed) = 0.2
robot2:     P(observe_closed | door_closed) = 0.8
robot2: 
  Observed: open
robot2:     P(observe_open | door_open) = 0.6
robot2:     P(observe_open | door_closed) = 0.2
robot2: 
  Correction calculations (before normalization):
robot2:     bel(open) ∝ P(open|obs) × bel^-(open) = 0.6 × 0.5000 = 0.3000
robot2:     bel(closed) ∝ P(open|closed) × bel^-(closed) = 0.2 × 0.5000 = 0.1000
robot2: 
  Final Normalization:
robot2:     Sum before normalization = 0.3000 + 0.1000 = 0.4000
robot2:     Normalization constant η = 1/0.4000 = 2.5000
robot2:     Final bel(open) = 0.3000 × 2.5000 = 0.7500
robot2:     Final bel(closed) = 0.1000 × 2.5000 = 0.2500
robot2:     Verification: 0.7500 + 0.2500 = 1.0000
robot2: 
  WHY NORMALIZE?
robot2:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot2:     - The proportionality constant ensures ∑P(x|z) = 1
robot2:     - This maintains the probability distribution property
robot2:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot2:     - Alternative: Additive update would violate probability axioms
robot2: 
=== BAYES FILTER COMPLETE FOR DOOR5 ===
robot2: Can pass through door5

--- robot1 Log ---
robot1: COMMUNICATION FAILED: Distance to robot2 = 4.67 > 3.0
robot1: 
=== BELIEF MERGING FOR DOOR5 ===
robot1: COMMUNICATION: Receiving belief from other robot
robot1: 
  Current robot's belief:
robot1:     bel_self(open) = 0.9643
robot1:     bel_self(closed) = 0.0357
robot1: 
  Other robot's belief:
robot1:     bel_other(open) = 0.7500
robot1:     bel_other(closed) = 0.2500
robot1: 
  WEIGHTED CONSENSUS FUSION:
robot1:     Communication weight (other robot's influence) = 0.30
robot1:     Self weight = 1 - 0.30 = 0.70
robot1:     Other weight = 0.30
robot1: 
  Fusion calculations:
robot1:     merged(open) = w_self × bel_self(open) + w_other × bel_other(open)
robot1:                  = 0.70 × 0.9643 + 0.30 × 0.7500
robot1:                  = 0.6750 + 0.2250 = 0.9000
robot1:     merged(closed) = w_self × bel_self(closed) + w_other × bel_other(closed)
robot1:                    = 0.70 × 0.0357 + 0.30 × 0.2500
robot1:                    = 0.0250 + 0.0750 = 0.1000
robot1: 
  Normalization check:
robot1:     Sum before normalization = 0.9000 + 0.1000 = 1.0000
robot1:     No normalization needed (sum ≈ 1.0)
robot1: 
  FUSION RESULT:
robot1:     Final merged(open) = 0.9000
robot1:     Final merged(closed) = 0.1000
robot1:     Change in open belief: -0.0643
robot1:     Change in closed belief: +0.0643
robot1: 
  WHY WEIGHTED AVERAGE?
robot1:     - Preserves uncertainty from both robots
robot1:     - Communication weight controls trust level
robot1:     - Alternative: Multiplication would assume independence
robot1:     - Alternative: Max would lose one robot's information
robot1:     - This method: Consensus-based distributed estimation
robot1: 
=== BELIEF MERGING COMPLETE FOR DOOR5 ===
robot1: Received belief update from robot2 for door5

--- robot1 Log ---
robot1: Moving to door3 at (2.0, 8.0)
robot1: Decided to push door3
robot1: Pushed door3 and observed it's open
robot1: 
=== BAYES FILTER UPDATE FOR DOOR3 ===
robot1: ACTION: push, OBSERVATION: open
robot1: 
Step 1: Prior belief bel(x_{t-1})
robot1:   bel(open) = 0.5000
robot1:   bel(closed) = 0.5000
robot1:   Verification: 0.5000 + 0.5000 = 1.0000
robot1: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot1:   Motion Model for action 'push':
robot1:     P(open | push, closed) = 0.8
robot1:     P(closed | push, closed) = 0.2
robot1:     P(open | push, open) = 1.0
robot1:     P(closed | push, open) = 0.0
robot1: 
  Prediction calculations:
robot1:     bel^-(open) = P(open|push,closed)*bel(closed) + P(open|push,open)*bel(open)
robot1:                 = 0.8 × 0.5000 + 1.0 × 0.5000
robot1:                 = 0.4000 + 0.5000 = 0.9000
robot1:     bel^-(closed) = P(closed|push,closed)*bel(closed) + P(closed|push,open)*bel(open)
robot1:                   = 0.2 × 0.5000 + 0.0 × 0.5000
robot1:                   = 0.1000 + 0.0000 = 0.1000
robot1: 
  Prediction result (before normalization):
robot1:     bel^-(open) = 0.9000
robot1:     bel^-(closed) = 0.1000
robot1:     Sum = 1.0000
robot1:   No normalization needed (sum ≈ 1.0)
robot1: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot1:   Sensor Model probabilities:
robot1:     P(observe_open | door_open) = 0.6
robot1:     P(observe_closed | door_open) = 0.4
robot1:     P(observe_open | door_closed) = 0.2
robot1:     P(observe_closed | door_closed) = 0.8
robot1: 
  Observed: open
robot1:     P(observe_open | door_open) = 0.6
robot1:     P(observe_open | door_closed) = 0.2
robot1: 
  Correction calculations (before normalization):
robot1:     bel(open) ∝ P(open|obs) × bel^-(open) = 0.6 × 0.9000 = 0.5400
robot1:     bel(closed) ∝ P(open|closed) × bel^-(closed) = 0.2 × 0.1000 = 0.0200
robot1: 
  Final Normalization:
robot1:     Sum before normalization = 0.5400 + 0.0200 = 0.5600
robot1:     Normalization constant η = 1/0.5600 = 1.7857
robot1:     Final bel(open) = 0.5400 × 1.7857 = 0.9643
robot1:     Final bel(closed) = 0.0200 × 1.7857 = 0.0357
robot1:     Verification: 0.9643 + 0.0357 = 1.0000
robot1: 
  WHY NORMALIZE?
robot1:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot1:     - The proportionality constant ensures ∑P(x|z) = 1
robot1:     - This maintains the probability distribution property
robot1:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot1:     - Alternative: Additive update would violate probability axioms
robot1: 
=== BAYES FILTER COMPLETE FOR DOOR3 ===
robot1: Can pass through door3

--- robot2 Log ---
robot2: COMMUNICATION SUCCESSFUL: Distance to robot1 = 0.94 <= 3.0
robot2: Moving to door1 at (3.0, 3.0)
robot2: Decided to do nothing door1
robot2: Observed door1 is closed
robot2: 
=== BAYES FILTER UPDATE FOR DOOR1 ===
robot2: ACTION: do nothing, OBSERVATION: closed
robot2: 
Step 1: Prior belief bel(x_{t-1})
robot2:   bel(open) = 0.5000
robot2:   bel(closed) = 0.5000
robot2:   Verification: 0.5000 + 0.5000 = 1.0000
robot2: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot2:   Motion Model for action 'do nothing':
robot2:     P(open | do_nothing, open) = 1.0
robot2:     P(closed | do_nothing, open) = 0.0
robot2:     P(open | do_nothing, closed) = 0.0
robot2:     P(closed | do_nothing, closed) = 1.0
robot2: 
  Prediction calculations:
robot2:     bel^-(open) = 0.0 × 0.5000 + 1.0 × 0.5000 = 0.5000
robot2:     bel^-(closed) = 1.0 × 0.5000 + 0.0 × 0.5000 = 0.5000
robot2: 
  Prediction result (before normalization):
robot2:     bel^-(open) = 0.5000
robot2:     bel^-(closed) = 0.5000
robot2:     Sum = 1.0000
robot2:   No normalization needed (sum ≈ 1.0)
robot2: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot2:   Sensor Model probabilities:
robot2:     P(observe_open | door_open) = 0.6
robot2:     P(observe_closed | door_open) = 0.4
robot2:     P(observe_open | door_closed) = 0.2
robot2:     P(observe_closed | door_closed) = 0.8
robot2: 
  Observed: closed
robot2:     P(observe_closed | door_open) = 0.4
robot2:     P(observe_closed | door_closed) = 0.8
robot2: 
  Correction calculations (before normalization):
robot2:     bel(open) ∝ P(closed|open) × bel^-(open) = 0.4 × 0.5000 = 0.2000
robot2:     bel(closed) ∝ P(closed|closed) × bel^-(closed) = 0.8 × 0.5000 = 0.4000
robot2: 
  Final Normalization:
robot2:     Sum before normalization = 0.2000 + 0.4000 = 0.6000
robot2:     Normalization constant η = 1/0.6000 = 1.6667
robot2:     Final bel(open) = 0.2000 × 1.6667 = 0.3333
robot2:     Final bel(closed) = 0.4000 × 1.6667 = 0.6667
robot2:     Verification: 0.3333 + 0.6667 = 1.0000
robot2: 
  WHY NORMALIZE?
robot2:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot2:     - The proportionality constant ensures ∑P(x|z) = 1
robot2:     - This maintains the probability distribution property
robot2:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot2:     - Alternative: Additive update would violate probability axioms
robot2: 
=== BAYES FILTER COMPLETE FOR DOOR1 ===
robot2: Cannot pass through door1 (belief: 0.333)

--- robot1 Log ---
robot1: COMMUNICATION FAILED: Distance to robot2 = 4.13 > 3.0
robot1: Moving to door4 at (9.0, 7.0)
robot1: Decided to push door4
robot1: Pushed door4 and observed it's open
robot1: 
=== BAYES FILTER UPDATE FOR DOOR4 ===
robot1: ACTION: push, OBSERVATION: open
robot1: 
Step 1: Prior belief bel(x_{t-1})
robot1:   bel(open) = 0.5000
robot1:   bel(closed) = 0.5000
robot1:   Verification: 0.5000 + 0.5000 = 1.0000
robot1: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot1:   Motion Model for action 'push':
robot1:     P(open | push, closed) = 0.8
robot1:     P(closed | push, closed) = 0.2
robot1:     P(open | push, open) = 1.0
robot1:     P(closed | push, open) = 0.0
robot1: 
  Prediction calculations:
robot1:     bel^-(open) = P(open|push,closed)*bel(closed) + P(open|push,open)*bel(open)
robot1:                 = 0.8 × 0.5000 + 1.0 × 0.5000
robot1:                 = 0.4000 + 0.5000 = 0.9000
robot1:     bel^-(closed) = P(closed|push,closed)*bel(closed) + P(closed|push,open)*bel(open)
robot1:                   = 0.2 × 0.5000 + 0.0 × 0.5000
robot1:                   = 0.1000 + 0.0000 = 0.1000
robot1: 
  Prediction result (before normalization):
robot1:     bel^-(open) = 0.9000
robot1:     bel^-(closed) = 0.1000
robot1:     Sum = 1.0000
robot1:   No normalization needed (sum ≈ 1.0)
robot1: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot1:   Sensor Model probabilities:
robot1:     P(observe_open | door_open) = 0.6
robot1:     P(observe_closed | door_open) = 0.4
robot1:     P(observe_open | door_closed) = 0.2
robot1:     P(observe_closed | door_closed) = 0.8
robot1: 
  Observed: open
robot1:     P(observe_open | door_open) = 0.6
robot1:     P(observe_open | door_closed) = 0.2
robot1: 
  Correction calculations (before normalization):
robot1:     bel(open) ∝ P(open|obs) × bel^-(open) = 0.6 × 0.9000 = 0.5400
robot1:     bel(closed) ∝ P(open|closed) × bel^-(closed) = 0.2 × 0.1000 = 0.0200
robot1: 
  Final Normalization:
robot1:     Sum before normalization = 0.5400 + 0.0200 = 0.5600
robot1:     Normalization constant η = 1/0.5600 = 1.7857
robot1:     Final bel(open) = 0.5400 × 1.7857 = 0.9643
robot1:     Final bel(closed) = 0.0200 × 1.7857 = 0.0357
robot1:     Verification: 0.9643 + 0.0357 = 1.0000
robot1: 
  WHY NORMALIZE?
robot1:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot1:     - The proportionality constant ensures ∑P(x|z) = 1
robot1:     - This maintains the probability distribution property
robot1:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot1:     - Alternative: Additive update would violate probability axioms
robot1: 
=== BAYES FILTER COMPLETE FOR DOOR4 ===
robot1: Can pass through door4

--- robot2 Log ---
robot2: COMMUNICATION FAILED: Distance to robot1 = 4.47 > 3.0
robot2: Moving to door1 at (3.0, 3.0)
robot2: Decided to push door1
robot2: Pushed door1 and observed it's closed
robot2: 
=== BAYES FILTER UPDATE FOR DOOR1 ===
robot2: ACTION: push, OBSERVATION: closed
robot2: 
Step 1: Prior belief bel(x_{t-1})
robot2:   bel(open) = 0.3333
robot2:   bel(closed) = 0.6667
robot2:   Verification: 0.3333 + 0.6667 = 1.0000
robot2: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot2:   Motion Model for action 'push':
robot2:     P(open | push, closed) = 0.8
robot2:     P(closed | push, closed) = 0.2
robot2:     P(open | push, open) = 1.0
robot2:     P(closed | push, open) = 0.0
robot2: 
  Prediction calculations:
robot2:     bel^-(open) = P(open|push,closed)*bel(closed) + P(open|push,open)*bel(open)
robot2:                 = 0.8 × 0.6667 + 1.0 × 0.3333
robot2:                 = 0.5333 + 0.3333 = 0.8667
robot2:     bel^-(closed) = P(closed|push,closed)*bel(closed) + P(closed|push,open)*bel(open)
robot2:                   = 0.2 × 0.6667 + 0.0 × 0.3333
robot2:                   = 0.1333 + 0.0000 = 0.1333
robot2: 
  Prediction result (before normalization):
robot2:     bel^-(open) = 0.8667
robot2:     bel^-(closed) = 0.1333
robot2:     Sum = 1.0000
robot2:   No normalization needed (sum ≈ 1.0)
robot2: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot2:   Sensor Model probabilities:
robot2:     P(observe_open | door_open) = 0.6
robot2:     P(observe_closed | door_open) = 0.4
robot2:     P(observe_open | door_closed) = 0.2
robot2:     P(observe_closed | door_closed) = 0.8
robot2: 
  Observed: closed
robot2:     P(observe_closed | door_open) = 0.4
robot2:     P(observe_closed | door_closed) = 0.8
robot2: 
  Correction calculations (before normalization):
robot2:     bel(open) ∝ P(closed|open) × bel^-(open) = 0.4 × 0.8667 = 0.3467
robot2:     bel(closed) ∝ P(closed|closed) × bel^-(closed) = 0.8 × 0.1333 = 0.1067
robot2: 
  Final Normalization:
robot2:     Sum before normalization = 0.3467 + 0.1067 = 0.4533
robot2:     Normalization constant η = 1/0.4533 = 2.2059
robot2:     Final bel(open) = 0.3467 × 2.2059 = 0.7647
robot2:     Final bel(closed) = 0.1067 × 2.2059 = 0.2353
robot2:     Verification: 0.7647 + 0.2353 = 1.0000
robot2: 
  WHY NORMALIZE?
robot2:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot2:     - The proportionality constant ensures ∑P(x|z) = 1
robot2:     - This maintains the probability distribution property
robot2:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot2:     - Alternative: Additive update would violate probability axioms
robot2: 
=== BAYES FILTER COMPLETE FOR DOOR1 ===
robot2: Can pass through door1

--- robot1 Log ---
robot1: COMMUNICATION FAILED: Distance to robot2 = 6.41 > 3.0
robot1: Moving to door2 at (8.0, 2.0)
robot1: Decided to push door2
robot1: Pushed door2 and observed it's closed
robot1: 
=== BAYES FILTER UPDATE FOR DOOR2 ===
robot1: ACTION: push, OBSERVATION: closed
robot1: 
Step 1: Prior belief bel(x_{t-1})
robot1:   bel(open) = 0.5000
robot1:   bel(closed) = 0.5000
robot1:   Verification: 0.5000 + 0.5000 = 1.0000
robot1: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot1:   Motion Model for action 'push':
robot1:     P(open | push, closed) = 0.8
robot1:     P(closed | push, closed) = 0.2
robot1:     P(open | push, open) = 1.0
robot1:     P(closed | push, open) = 0.0
robot1: 
  Prediction calculations:
robot1:     bel^-(open) = P(open|push,closed)*bel(closed) + P(open|push,open)*bel(open)
robot1:                 = 0.8 × 0.5000 + 1.0 × 0.5000
robot1:                 = 0.4000 + 0.5000 = 0.9000
robot1:     bel^-(closed) = P(closed|push,closed)*bel(closed) + P(closed|push,open)*bel(open)
robot1:                   = 0.2 × 0.5000 + 0.0 × 0.5000
robot1:                   = 0.1000 + 0.0000 = 0.1000
robot1: 
  Prediction result (before normalization):
robot1:     bel^-(open) = 0.9000
robot1:     bel^-(closed) = 0.1000
robot1:     Sum = 1.0000
robot1:   No normalization needed (sum ≈ 1.0)
robot1: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot1:   Sensor Model probabilities:
robot1:     P(observe_open | door_open) = 0.6
robot1:     P(observe_closed | door_open) = 0.4
robot1:     P(observe_open | door_closed) = 0.2
robot1:     P(observe_closed | door_closed) = 0.8
robot1: 
  Observed: closed
robot1:     P(observe_closed | door_open) = 0.4
robot1:     P(observe_closed | door_closed) = 0.8
robot1: 
  Correction calculations (before normalization):
robot1:     bel(open) ∝ P(closed|open) × bel^-(open) = 0.4 × 0.9000 = 0.3600
robot1:     bel(closed) ∝ P(closed|closed) × bel^-(closed) = 0.8 × 0.1000 = 0.0800
robot1: 
  Final Normalization:
robot1:     Sum before normalization = 0.3600 + 0.0800 = 0.4400
robot1:     Normalization constant η = 1/0.4400 = 2.2727
robot1:     Final bel(open) = 0.3600 × 2.2727 = 0.8182
robot1:     Final bel(closed) = 0.0800 × 2.2727 = 0.1818
robot1:     Verification: 0.8182 + 0.1818 = 1.0000
robot1: 
  WHY NORMALIZE?
robot1:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot1:     - The proportionality constant ensures ∑P(x|z) = 1
robot1:     - This maintains the probability distribution property
robot1:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot1:     - Alternative: Additive update would violate probability axioms
robot1: 
=== BAYES FILTER COMPLETE FOR DOOR2 ===
robot1: Can pass through door2

--- robot2 Log ---
robot2: COMMUNICATION FAILED: Distance to robot1 = 6.41 > 3.0
robot2: Moving to door3 at (2.0, 8.0)
robot2: Decided to do nothing door3
robot2: Observed door3 is open
robot2: 
=== BAYES FILTER UPDATE FOR DOOR3 ===
robot2: ACTION: do nothing, OBSERVATION: open
robot2: 
Step 1: Prior belief bel(x_{t-1})
robot2:   bel(open) = 0.5000
robot2:   bel(closed) = 0.5000
robot2:   Verification: 0.5000 + 0.5000 = 1.0000
robot2: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot2:   Motion Model for action 'do nothing':
robot2:     P(open | do_nothing, open) = 1.0
robot2:     P(closed | do_nothing, open) = 0.0
robot2:     P(open | do_nothing, closed) = 0.0
robot2:     P(closed | do_nothing, closed) = 1.0
robot2: 
  Prediction calculations:
robot2:     bel^-(open) = 0.0 × 0.5000 + 1.0 × 0.5000 = 0.5000
robot2:     bel^-(closed) = 1.0 × 0.5000 + 0.0 × 0.5000 = 0.5000
robot2: 
  Prediction result (before normalization):
robot2:     bel^-(open) = 0.5000
robot2:     bel^-(closed) = 0.5000
robot2:     Sum = 1.0000
robot2:   No normalization needed (sum ≈ 1.0)
robot2: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot2:   Sensor Model probabilities:
robot2:     P(observe_open | door_open) = 0.6
robot2:     P(observe_closed | door_open) = 0.4
robot2:     P(observe_open | door_closed) = 0.2
robot2:     P(observe_closed | door_closed) = 0.8
robot2: 
  Observed: open
robot2:     P(observe_open | door_open) = 0.6
robot2:     P(observe_open | door_closed) = 0.2
robot2: 
  Correction calculations (before normalization):
robot2:     bel(open) ∝ P(open|obs) × bel^-(open) = 0.6 × 0.5000 = 0.3000
robot2:     bel(closed) ∝ P(open|closed) × bel^-(closed) = 0.2 × 0.5000 = 0.1000
robot2: 
  Final Normalization:
robot2:     Sum before normalization = 0.3000 + 0.1000 = 0.4000
robot2:     Normalization constant η = 1/0.4000 = 2.5000
robot2:     Final bel(open) = 0.3000 × 2.5000 = 0.7500
robot2:     Final bel(closed) = 0.1000 × 2.5000 = 0.2500
robot2:     Verification: 0.7500 + 0.2500 = 1.0000
robot2: 
  WHY NORMALIZE?
robot2:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot2:     - The proportionality constant ensures ∑P(x|z) = 1
robot2:     - This maintains the probability distribution property
robot2:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot2:     - Alternative: Additive update would violate probability axioms
robot2: 
=== BAYES FILTER COMPLETE FOR DOOR3 ===
robot2: Can pass through door3

--- robot2 Log ---
robot2: COMMUNICATION FAILED: Distance to robot1 = 7.89 > 3.0
robot2: Moving to door2 at (8.0, 2.0)
robot2: Decided to do nothing door2
robot2: Observed door2 is closed
robot2: 
=== BAYES FILTER UPDATE FOR DOOR2 ===
robot2: ACTION: do nothing, OBSERVATION: closed
robot2: 
Step 1: Prior belief bel(x_{t-1})
robot2:   bel(open) = 0.5000
robot2:   bel(closed) = 0.5000
robot2:   Verification: 0.5000 + 0.5000 = 1.0000
robot2: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot2:   Motion Model for action 'do nothing':
robot2:     P(open | do_nothing, open) = 1.0
robot2:     P(closed | do_nothing, open) = 0.0
robot2:     P(open | do_nothing, closed) = 0.0
robot2:     P(closed | do_nothing, closed) = 1.0
robot2: 
  Prediction calculations:
robot2:     bel^-(open) = 0.0 × 0.5000 + 1.0 × 0.5000 = 0.5000
robot2:     bel^-(closed) = 1.0 × 0.5000 + 0.0 × 0.5000 = 0.5000
robot2: 
  Prediction result (before normalization):
robot2:     bel^-(open) = 0.5000
robot2:     bel^-(closed) = 0.5000
robot2:     Sum = 1.0000
robot2:   No normalization needed (sum ≈ 1.0)
robot2: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot2:   Sensor Model probabilities:
robot2:     P(observe_open | door_open) = 0.6
robot2:     P(observe_closed | door_open) = 0.4
robot2:     P(observe_open | door_closed) = 0.2
robot2:     P(observe_closed | door_closed) = 0.8
robot2: 
  Observed: closed
robot2:     P(observe_closed | door_open) = 0.4
robot2:     P(observe_closed | door_closed) = 0.8
robot2: 
  Correction calculations (before normalization):
robot2:     bel(open) ∝ P(closed|open) × bel^-(open) = 0.4 × 0.5000 = 0.2000
robot2:     bel(closed) ∝ P(closed|closed) × bel^-(closed) = 0.8 × 0.5000 = 0.4000
robot2: 
  Final Normalization:
robot2:     Sum before normalization = 0.2000 + 0.4000 = 0.6000
robot2:     Normalization constant η = 1/0.6000 = 1.6667
robot2:     Final bel(open) = 0.2000 × 1.6667 = 0.3333
robot2:     Final bel(closed) = 0.4000 × 1.6667 = 0.6667
robot2:     Verification: 0.3333 + 0.6667 = 1.0000
robot2: 
  WHY NORMALIZE?
robot2:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot2:     - The proportionality constant ensures ∑P(x|z) = 1
robot2:     - This maintains the probability distribution property
robot2:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot2:     - Alternative: Additive update would violate probability axioms
robot2: 
=== BAYES FILTER COMPLETE FOR DOOR2 ===
robot2: Cannot pass through door2 (belief: 0.333)

--- robot1 Log ---
robot1: COMMUNICATION FAILED: Distance to robot2 = 4.93 > 3.0
robot1: 
=== BELIEF MERGING FOR DOOR2 ===
robot1: COMMUNICATION: Receiving belief from other robot
robot1: 
  Current robot's belief:
robot1:     bel_self(open) = 0.8182
robot1:     bel_self(closed) = 0.1818
robot1: 
  Other robot's belief:
robot1:     bel_other(open) = 0.3333
robot1:     bel_other(closed) = 0.6667
robot1: 
  WEIGHTED CONSENSUS FUSION:
robot1:     Communication weight (other robot's influence) = 0.30
robot1:     Self weight = 1 - 0.30 = 0.70
robot1:     Other weight = 0.30
robot1: 
  Fusion calculations:
robot1:     merged(open) = w_self × bel_self(open) + w_other × bel_other(open)
robot1:                  = 0.70 × 0.8182 + 0.30 × 0.3333
robot1:                  = 0.5727 + 0.1000 = 0.6727
robot1:     merged(closed) = w_self × bel_self(closed) + w_other × bel_other(closed)
robot1:                    = 0.70 × 0.1818 + 0.30 × 0.6667
robot1:                    = 0.1273 + 0.2000 = 0.3273
robot1: 
  Normalization check:
robot1:     Sum before normalization = 0.6727 + 0.3273 = 1.0000
robot1:     No normalization needed (sum ≈ 1.0)
robot1: 
  FUSION RESULT:
robot1:     Final merged(open) = 0.6727
robot1:     Final merged(closed) = 0.3273
robot1:     Change in open belief: -0.1455
robot1:     Change in closed belief: +0.1455
robot1: 
  WHY WEIGHTED AVERAGE?
robot1:     - Preserves uncertainty from both robots
robot1:     - Communication weight controls trust level
robot1:     - Alternative: Multiplication would assume independence
robot1:     - Alternative: Max would lose one robot's information
robot1:     - This method: Consensus-based distributed estimation
robot1: 
=== BELIEF MERGING COMPLETE FOR DOOR2 ===
robot1: Received belief update from robot2 for door2

--- robot2 Log ---
robot2: COMMUNICATION SUCCESSFUL: Distance to robot1 = 0.47 <= 3.0
robot2: Moving to door2 at (8.0, 2.0)
robot2: Decided to push door2
robot2: Pushed door2 and observed it's open
robot2: 
=== BAYES FILTER UPDATE FOR DOOR2 ===
robot2: ACTION: push, OBSERVATION: open
robot2: 
Step 1: Prior belief bel(x_{t-1})
robot2:   bel(open) = 0.3333
robot2:   bel(closed) = 0.6667
robot2:   Verification: 0.3333 + 0.6667 = 1.0000
robot2: 
Step 2: PREDICTION STEP - Motion Model P(x_t | u_t, x_{t-1})
robot2:   Motion Model for action 'push':
robot2:     P(open | push, closed) = 0.8
robot2:     P(closed | push, closed) = 0.2
robot2:     P(open | push, open) = 1.0
robot2:     P(closed | push, open) = 0.0
robot2: 
  Prediction calculations:
robot2:     bel^-(open) = P(open|push,closed)*bel(closed) + P(open|push,open)*bel(open)
robot2:                 = 0.8 × 0.6667 + 1.0 × 0.3333
robot2:                 = 0.5333 + 0.3333 = 0.8667
robot2:     bel^-(closed) = P(closed|push,closed)*bel(closed) + P(closed|push,open)*bel(open)
robot2:                   = 0.2 × 0.6667 + 0.0 × 0.3333
robot2:                   = 0.1333 + 0.0000 = 0.1333
robot2: 
  Prediction result (before normalization):
robot2:     bel^-(open) = 0.8667
robot2:     bel^-(closed) = 0.1333
robot2:     Sum = 1.0000
robot2:   No normalization needed (sum ≈ 1.0)
robot2: 
Step 3: CORRECTION STEP - Sensor Model P(z_t | x_t)
robot2:   Sensor Model probabilities:
robot2:     P(observe_open | door_open) = 0.6
robot2:     P(observe_closed | door_open) = 0.4
robot2:     P(observe_open | door_closed) = 0.2
robot2:     P(observe_closed | door_closed) = 0.8
robot2: 
  Observed: open
robot2:     P(observe_open | door_open) = 0.6
robot2:     P(observe_open | door_closed) = 0.2
robot2: 
  Correction calculations (before normalization):
robot2:     bel(open) ∝ P(open|obs) × bel^-(open) = 0.6 × 0.8667 = 0.5200
robot2:     bel(closed) ∝ P(open|closed) × bel^-(closed) = 0.2 × 0.1333 = 0.0267
robot2: 
  Final Normalization:
robot2:     Sum before normalization = 0.5200 + 0.0267 = 0.5467
robot2:     Normalization constant η = 1/0.5467 = 1.8293
robot2:     Final bel(open) = 0.5200 × 1.8293 = 0.9512
robot2:     Final bel(closed) = 0.0267 × 1.8293 = 0.0488
robot2:     Verification: 0.9512 + 0.0488 = 1.0000
robot2: 
  WHY NORMALIZE?
robot2:     - Bayes rule gives us P(x|z) ∝ P(z|x) × P(x)
robot2:     - The proportionality constant ensures ∑P(x|z) = 1
robot2:     - This maintains the probability distribution property
robot2:     - Alternative: Maximum likelihood would pick max, losing uncertainty info
robot2:     - Alternative: Additive update would violate probability axioms
robot2: 
=== BAYES FILTER COMPLETE FOR DOOR2 ===
robot2: Can pass through door2

==================================================
FINAL SUMMARY
==================================================
robot1 passed through doors: ['door1', 'door5', 'door3', 'door4', 'door2']
robot2 passed through doors: ['door4', 'door5', 'door1', 'door3', 'door2']
robot1 can pass all doors: True
robot2 can pass all doors: True

Final beliefs for all doors:
door1: robot1 open=0.818, robot2 open=0.765
door2: robot1 open=0.673, robot2 open=0.951
door3: robot1 open=0.964, robot2 open=0.750
door4: robot1 open=0.964, robot2 open=0.750
door5: robot1 open=0.900, robot2 open=0.750

Communication Statistics:
Communication distance threshold: 3.0
robot1 communication weight: 0.3
robot2 communication weight: 0.4
